<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Vaish Shrivastava</title>

    <meta name="author" content="Vaish Shrivastava">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Vaish Shrivastava
                </p>
                <p>I am a Master's Student in Computer Science at <a href="https://www.cs.stanford.edu/">Stanford University</a>, where I am grateful to be advised by Professor <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>. I am also a Student Researcher at the <a href="https://allenai.org/">Allen Institute for AI</a>. 
                </p>
                <p>
                  Previously, I was an Applied Scientist at <a href="https://www.microsoft.com/en-us/research/group/msai/">Microsoft</a>, where I worked on developing parameter-efficient NLP systems deployed to millions of users! Prior to joining Microsoft, I received my Bachelor's in Computer Science degree from <a href="https://www.caltech.edu/">Caltech</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:vaish.shrivastava@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Vaishnavi_Shrivastava_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/Vaishnavi_Shrivastava_PhD_Research_Statement.pdf">Research Statement</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=N0nX2VsAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/VaishShrivas">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/vaish-shrivastava/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/vshrivas">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/vaish_image_glasses.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/vaish_image_glasses.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in building trustworthy large language models that are capable of reasoning robustly. I am particularly excited about teaching models to express their uncertainty, reason in consistent ways, perform long-horizon planning, and continually adapt to real-world signals.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/llamas_paper.png" alt="safs_small" width="190" height="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2311.08877">
                  <span class="papertitle">Llamas Know What GPTs Don't Show: Surrogate Models for Confidence Estimation</span>
                </a>
                <br>
                <strong>Vaishnavi Shrivastava</strong>, <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>, <a href="https://ananyakumar.wordpress.com/">Ananya Kumar</a>
                <br>
                <em>arXiv</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2311.08877">arXiv</a>
                <p>We study if the uncertainty of black-box models can be approximated through open, white-box models and find that confidence scores can transfer from weaker, white-box models like Llama 2 to stronger, black-box models like GPT-4. We discover that different LLMs tend to make similar mistakes, potentially enabling transfer of their ingrained uncertainty.</a></p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/consistency_finetuning_paper1.png" alt="fast-texture" width="190" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2310.01846">
                  <span class="papertitle">Benchmarking and Improving Generator-Validator Consistency of Language Models</span>
                </a>
                <br>
                <a href="https://xiangli1999.github.io/">Xiang Lisa Li</a>, <strong>Vaishnavi Shrivastava</strong>, <a href="https://siyan-sylvia-li.com/">Siyan Li</a>, <a href="https://thashim.github.io/">Tatsunori Hashimoto</a>, <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>
                <br>
                <em>ICLR</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2310.01846">arXiv</a>
                <p>We find that models tend to be inconsistent when generating an answer (responding with '15' to 'What is 7+8?') vs when validating their answers (saying 'No' to 'Is 7+8=15?') - a behavior we term 'Generator-Validator (GV) inconsistency'. We introduce consistency fine-tuning, a self-supervised approach to reduce GV inconsistencies in language models.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/bias_paper2.png" alt="prl" width="190" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2311.04892">
                  <span class="papertitle">Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs</span>
                </a>
                <br>
                <a href="https://shashankgupta.info/">Shashank Gupta</a>, <strong>Vaishnavi Shrivastava</strong>, <a href="https://ameet-1997.github.io/">Ameet Deshpande</a>, <a href="http://ashwinkalyan.com/">Ashwin Kalyan</a>, <a href="https://allenai.org/team/peterc">Peter Clark</a>, <a href="https://allenai.org/team/ashishs">Ashish Sabharwal</a>, <a href="https://allenai.org/team/tushark">Tushar Khot</a>
                <br>
                <em>ICLR</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2311.04892">arXiv</a>
                <p>We show that LLMs provide biased simulations of human behavior and exhibit stereotypical and harmful reasoning patterns while adopting personas of different socio-demographic groups. For instance, ChatGPT frequently makes limiting and incorrect assumptions about a physically-disabled person ("As a physically-disabled person, I can't move and thus I am not good at math.").</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/user_identifier_paper.png" alt="blind-date" width="190" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://aclanthology.org/2022.naacl-main.252/">
                  <span class="papertitle">UserIdentifier: Implicit User Representations for Simple and Effective Personalized Sentiment Analysis</span>
                </a>
                <br>
                <a href="https://cseweb.ucsd.edu/~fmireshg/">Fatemehsadat Mireshghallah</a>, <strong>Vaishnavi Shrivastava</strong>, <a href="https://www.microsoft.com/en-us/research/people/milads/">Milad Shokouhi</a>, <a href="https://cseweb.ucsd.edu/~tberg/">Taylor Berg-Kirkpatrick</a>, <a href="https://www.microsoft.com/en-us/research/people/rsim/">Robert Sim</a>, <a href="https://www.linkedin.com/in/dimdimitriadis/">Dimitrios Dimitriadis</a>
                <br>
                <em>NAACL</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2110.00135">arXiv</a>
                <p>We investigate using non-trainable, user-specific prompts for user-personalization, instead of trainable embeddings. We demonstrate that we can outperform SOTA prefix-tuning based results on a suite of sentiment analysis by up to 13%.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/low_cost_transformer.png" alt="clean-usnob" width="190" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2111.13999">
                  <span class="papertitle">Exploring Low-Cost Transformer Model Compression for Large-Scale
                    Commercial Reply Suggestions</span>
                </a>
                <br>
                <strong>Vaishnavi Shrivastava</strong>, <a href="https://www.linkedin.com/in/rgaonkar">Radhika Gaonkar</a>, <a href="https://shashankgupta.info/">Shashank Gupta</a>, Abhishek Jha
                <br>
                <em>arXiv</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2111.13999">arXiv</a>
                <p>We study low-cost methods to compress Transformer bi-encoder based reply suggestion system, reducing training and inference times by 42% and 35% respectively. We investigate how dataset size, pre-trained model use, and domain adaptation of the pre-trained model affected the performance of compression techniques.</p>
              </td>
            </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  <center>Website source code from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.</center> 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
